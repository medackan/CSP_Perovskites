{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwtxrKRlUtQ4"
   },
   "source": [
    "**CLASSIFICATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhQrWJmBEE1I"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('M4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Fu4JCmo1Bpm",
    "outputId": "969e0a1b-d8ac-40c7-eea8-3846d32574b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è± Run 1 of 5...\n",
      "\n",
      "üîß Tuning Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.6322, F1: 0.6233, Precision: 0.6239, Recall: 0.6322, ROC AUC: 0.8378, ‚è± Time: 10.65 sec\n",
      "\n",
      "üîß Tuning Naive Bayes...\n",
      "Naive Bayes Accuracy: 0.5346, F1: 0.5111, Precision: 0.5212, Recall: 0.5346, ROC AUC: 0.7752, ‚è± Time: 0.08 sec\n",
      "\n",
      "üîß Tuning K-Nearest Neighbors...\n",
      "K-Nearest Neighbors Accuracy: 0.9090, F1: 0.9065, Precision: 0.9121, Recall: 0.9090, ROC AUC: 0.9685, ‚è± Time: 3.97 sec\n",
      "\n",
      "üîß Tuning Decision Tree...\n",
      "Decision Tree Accuracy: 0.8777, F1: 0.8768, Precision: 0.8765, Recall: 0.8777, ROC AUC: 0.9185, ‚è± Time: 13.03 sec\n",
      "\n",
      "üîß Tuning Random Forest...\n",
      "Random Forest Accuracy: 0.9320, F1: 0.9315, Precision: 0.9314, Recall: 0.9320, ROC AUC: 0.9922, ‚è± Time: 481.95 sec\n",
      "\n",
      "üîß Tuning Extra Trees...\n",
      "Extra Trees Accuracy: 0.9419, F1: 0.9414, Precision: 0.9413, Recall: 0.9419, ROC AUC: 0.9944, ‚è± Time: 23.81 sec\n",
      "\n",
      "üîß Tuning AdaBoost...\n",
      "AdaBoost Accuracy: 0.7269, F1: 0.7242, Precision: 0.7274, Recall: 0.7269, ROC AUC: 0.9108, ‚è± Time: 112.17 sec\n",
      "\n",
      "üîß Tuning Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.9143, F1: 0.9135, Precision: 0.9137, Recall: 0.9143, ROC AUC: 0.9852, ‚è± Time: 854.56 sec\n",
      "\n",
      "üîß Tuning XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:21:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8921, F1: 0.8910, Precision: 0.8909, Recall: 0.8921, ROC AUC: 0.9805, ‚è± Time: 30.52 sec\n",
      "\n",
      "üîß Tuning LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6258\n",
      "[LightGBM] [Info] Number of data points in the train set: 9712, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Accuracy: 0.9411, F1: 0.9409, Precision: 0.9410, Recall: 0.9411, ROC AUC: 0.9927, ‚è± Time: 59.01 sec\n",
      "\n",
      "üîß Tuning Support Vector Machine...\n",
      "Support Vector Machine Accuracy: 0.8526, F1: 0.8496, Precision: 0.8514, Recall: 0.8526, ROC AUC: 0.9696, ‚è± Time: 161.65 sec\n",
      "\n",
      "üîß Tuning Neural Network...\n",
      "Neural Network Accuracy: 0.9325, F1: 0.9318, Precision: 0.9322, Recall: 0.9325, ROC AUC: 0.9864, ‚è± Time: 296.65 sec\n",
      "\n",
      "‚è± Run 2 of 5...\n",
      "\n",
      "üîß Tuning Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.6273, F1: 0.6183, Precision: 0.6172, Recall: 0.6273, ROC AUC: 0.8384, ‚è± Time: 1.83 sec\n",
      "\n",
      "üîß Tuning Naive Bayes...\n",
      "Naive Bayes Accuracy: 0.5231, F1: 0.4983, Precision: 0.5077, Recall: 0.5231, ROC AUC: 0.7663, ‚è± Time: 0.08 sec\n",
      "\n",
      "üîß Tuning K-Nearest Neighbors...\n",
      "K-Nearest Neighbors Accuracy: 0.9044, F1: 0.9024, Precision: 0.9057, Recall: 0.9044, ROC AUC: 0.9692, ‚è± Time: 0.35 sec\n",
      "\n",
      "üîß Tuning Decision Tree...\n",
      "Decision Tree Accuracy: 0.8707, F1: 0.8700, Precision: 0.8696, Recall: 0.8707, ROC AUC: 0.9138, ‚è± Time: 0.45 sec\n",
      "\n",
      "üîß Tuning Random Forest...\n",
      "Random Forest Accuracy: 0.9345, F1: 0.9340, Precision: 0.9339, Recall: 0.9345, ROC AUC: 0.9931, ‚è± Time: 43.21 sec\n",
      "\n",
      "üîß Tuning Extra Trees...\n",
      "Extra Trees Accuracy: 0.9502, F1: 0.9499, Precision: 0.9498, Recall: 0.9502, ROC AUC: 0.9953, ‚è± Time: 5.10 sec\n",
      "\n",
      "üîß Tuning AdaBoost...\n",
      "AdaBoost Accuracy: 0.7405, F1: 0.7386, Precision: 0.7428, Recall: 0.7405, ROC AUC: 0.9066, ‚è± Time: 19.19 sec\n",
      "\n",
      "üîß Tuning Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.9057, F1: 0.9050, Precision: 0.9046, Recall: 0.9057, ROC AUC: 0.9859, ‚è± Time: 96.59 sec\n",
      "\n",
      "üîß Tuning XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:33:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8789, F1: 0.8776, Precision: 0.8772, Recall: 0.8789, ROC AUC: 0.9813, ‚è± Time: 2.18 sec\n",
      "\n",
      "üîß Tuning LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6264\n",
      "[LightGBM] [Info] Number of data points in the train set: 9712, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Accuracy: 0.9362, F1: 0.9359, Precision: 0.9358, Recall: 0.9362, ROC AUC: 0.9932, ‚è± Time: 4.45 sec\n",
      "\n",
      "üîß Tuning Support Vector Machine...\n",
      "Support Vector Machine Accuracy: 0.8431, F1: 0.8399, Precision: 0.8408, Recall: 0.8431, ROC AUC: 0.9696, ‚è± Time: 21.73 sec\n",
      "\n",
      "üîß Tuning Neural Network...\n",
      "Neural Network Accuracy: 0.9296, F1: 0.9292, Precision: 0.9290, Recall: 0.9296, ROC AUC: 0.9870, ‚è± Time: 21.69 sec\n",
      "\n",
      "‚è± Run 3 of 5...\n",
      "\n",
      "üîß Tuning Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.6417, F1: 0.6353, Precision: 0.6347, Recall: 0.6417, ROC AUC: 0.8447, ‚è± Time: 2.98 sec\n",
      "\n",
      "üîß Tuning Naive Bayes...\n",
      "Naive Bayes Accuracy: 0.5379, F1: 0.5175, Precision: 0.5258, Recall: 0.5379, ROC AUC: 0.7731, ‚è± Time: 0.06 sec\n",
      "\n",
      "üîß Tuning K-Nearest Neighbors...\n",
      "K-Nearest Neighbors Accuracy: 0.9193, F1: 0.9175, Precision: 0.9209, Recall: 0.9193, ROC AUC: 0.9728, ‚è± Time: 0.37 sec\n",
      "\n",
      "üîß Tuning Decision Tree...\n",
      "Decision Tree Accuracy: 0.8781, F1: 0.8781, Precision: 0.8782, Recall: 0.8781, ROC AUC: 0.9187, ‚è± Time: 0.45 sec\n",
      "\n",
      "üîß Tuning Random Forest...\n",
      "Random Forest Accuracy: 0.9456, F1: 0.9454, Precision: 0.9453, Recall: 0.9456, ROC AUC: 0.9945, ‚è± Time: 42.85 sec\n",
      "\n",
      "üîß Tuning Extra Trees...\n",
      "Extra Trees Accuracy: 0.9572, F1: 0.9570, Precision: 0.9571, Recall: 0.9572, ROC AUC: 0.9963, ‚è± Time: 5.49 sec\n",
      "\n",
      "üîß Tuning AdaBoost...\n",
      "AdaBoost Accuracy: 0.7409, F1: 0.7404, Precision: 0.7445, Recall: 0.7409, ROC AUC: 0.9113, ‚è± Time: 20.31 sec\n",
      "\n",
      "üîß Tuning Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.9156, F1: 0.9153, Precision: 0.9152, Recall: 0.9156, ROC AUC: 0.9877, ‚è± Time: 100.29 sec\n",
      "\n",
      "üîß Tuning XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:37:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.9028, F1: 0.9021, Precision: 0.9023, Recall: 0.9028, ROC AUC: 0.9837, ‚è± Time: 2.28 sec\n",
      "\n",
      "üîß Tuning LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6261\n",
      "[LightGBM] [Info] Number of data points in the train set: 9712, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Accuracy: 0.9485, F1: 0.9485, Precision: 0.9485, Recall: 0.9485, ROC AUC: 0.9945, ‚è± Time: 5.49 sec\n",
      "\n",
      "üîß Tuning Support Vector Machine...\n",
      "Support Vector Machine Accuracy: 0.8624, F1: 0.8601, Precision: 0.8603, Recall: 0.8624, ROC AUC: 0.9720, ‚è± Time: 21.10 sec\n",
      "\n",
      "üîß Tuning Neural Network...\n",
      "Neural Network Accuracy: 0.9316, F1: 0.9311, Precision: 0.9314, Recall: 0.9316, ROC AUC: 0.9896, ‚è± Time: 24.44 sec\n",
      "\n",
      "‚è± Run 4 of 5...\n",
      "\n",
      "üîß Tuning Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.6277, F1: 0.6194, Precision: 0.6194, Recall: 0.6277, ROC AUC: 0.8400, ‚è± Time: 2.51 sec\n",
      "\n",
      "üîß Tuning Naive Bayes...\n",
      "Naive Bayes Accuracy: 0.5313, F1: 0.5063, Precision: 0.5179, Recall: 0.5313, ROC AUC: 0.7695, ‚è± Time: 0.08 sec\n",
      "\n",
      "üîß Tuning K-Nearest Neighbors...\n",
      "K-Nearest Neighbors Accuracy: 0.9131, F1: 0.9115, Precision: 0.9142, Recall: 0.9131, ROC AUC: 0.9738, ‚è± Time: 0.34 sec\n",
      "\n",
      "üîß Tuning Decision Tree...\n",
      "Decision Tree Accuracy: 0.8678, F1: 0.8672, Precision: 0.8671, Recall: 0.8678, ROC AUC: 0.9119, ‚è± Time: 0.46 sec\n",
      "\n",
      "üîß Tuning Random Forest...\n",
      "Random Forest Accuracy: 0.9419, F1: 0.9416, Precision: 0.9415, Recall: 0.9419, ROC AUC: 0.9935, ‚è± Time: 44.05 sec\n",
      "\n",
      "üîß Tuning Extra Trees...\n",
      "Extra Trees Accuracy: 0.9498, F1: 0.9495, Precision: 0.9494, Recall: 0.9498, ROC AUC: 0.9957, ‚è± Time: 4.42 sec\n",
      "\n",
      "üîß Tuning AdaBoost...\n",
      "AdaBoost Accuracy: 0.7212, F1: 0.7205, Precision: 0.7294, Recall: 0.7212, ROC AUC: 0.9053, ‚è± Time: 20.01 sec\n",
      "\n",
      "üîß Tuning Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.9123, F1: 0.9119, Precision: 0.9118, Recall: 0.9123, ROC AUC: 0.9867, ‚è± Time: 95.90 sec\n",
      "\n",
      "üîß Tuning XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:40:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8843, F1: 0.8834, Precision: 0.8836, Recall: 0.8843, ROC AUC: 0.9815, ‚è± Time: 3.09 sec\n",
      "\n",
      "üîß Tuning LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6263\n",
      "[LightGBM] [Info] Number of data points in the train set: 9712, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Accuracy: 0.9456, F1: 0.9454, Precision: 0.9454, Recall: 0.9456, ROC AUC: 0.9940, ‚è± Time: 4.68 sec\n",
      "\n",
      "üîß Tuning Support Vector Machine...\n",
      "Support Vector Machine Accuracy: 0.8620, F1: 0.8598, Precision: 0.8612, Recall: 0.8620, ROC AUC: 0.9707, ‚è± Time: 21.77 sec\n",
      "\n",
      "üîß Tuning Neural Network...\n",
      "Neural Network Accuracy: 0.9395, F1: 0.9389, Precision: 0.9391, Recall: 0.9395, ROC AUC: 0.9886, ‚è± Time: 21.59 sec\n",
      "\n",
      "‚è± Run 5 of 5...\n",
      "\n",
      "üîß Tuning Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.6318, F1: 0.6258, Precision: 0.6249, Recall: 0.6318, ROC AUC: 0.8438, ‚è± Time: 2.28 sec\n",
      "\n",
      "üîß Tuning Naive Bayes...\n",
      "Naive Bayes Accuracy: 0.5375, F1: 0.5167, Precision: 0.5246, Recall: 0.5375, ROC AUC: 0.7762, ‚è± Time: 0.04 sec\n",
      "\n",
      "üîß Tuning K-Nearest Neighbors...\n",
      "K-Nearest Neighbors Accuracy: 0.9090, F1: 0.9071, Precision: 0.9104, Recall: 0.9090, ROC AUC: 0.9676, ‚è± Time: 0.37 sec\n",
      "\n",
      "üîß Tuning Decision Tree...\n",
      "Decision Tree Accuracy: 0.8612, F1: 0.8605, Precision: 0.8603, Recall: 0.8612, ROC AUC: 0.9075, ‚è± Time: 0.55 sec\n",
      "\n",
      "üîß Tuning Random Forest...\n",
      "Random Forest Accuracy: 0.9341, F1: 0.9338, Precision: 0.9336, Recall: 0.9341, ROC AUC: 0.9924, ‚è± Time: 43.52 sec\n",
      "\n",
      "üîß Tuning Extra Trees...\n",
      "Extra Trees Accuracy: 0.9514, F1: 0.9512, Precision: 0.9512, Recall: 0.9514, ROC AUC: 0.9948, ‚è± Time: 4.41 sec\n",
      "\n",
      "üîß Tuning AdaBoost...\n",
      "AdaBoost Accuracy: 0.7158, F1: 0.7136, Precision: 0.7187, Recall: 0.7158, ROC AUC: 0.9002, ‚è± Time: 19.89 sec\n",
      "\n",
      "üîß Tuning Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.9061, F1: 0.9057, Precision: 0.9055, Recall: 0.9061, ROC AUC: 0.9851, ‚è± Time: 95.99 sec\n",
      "\n",
      "üîß Tuning XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:44:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8830, F1: 0.8819, Precision: 0.8815, Recall: 0.8830, ROC AUC: 0.9792, ‚è± Time: 4.15 sec\n",
      "\n",
      "üîß Tuning LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6256\n",
      "[LightGBM] [Info] Number of data points in the train set: 9712, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Accuracy: 0.9390, F1: 0.9390, Precision: 0.9389, Recall: 0.9390, ROC AUC: 0.9917, ‚è± Time: 4.52 sec\n",
      "\n",
      "üîß Tuning Support Vector Machine...\n",
      "Support Vector Machine Accuracy: 0.8493, F1: 0.8470, Precision: 0.8474, Recall: 0.8493, ROC AUC: 0.9696, ‚è± Time: 21.83 sec\n",
      "\n",
      "üîß Tuning Neural Network...\n",
      "Neural Network Accuracy: 0.9292, F1: 0.9283, Precision: 0.9282, Recall: 0.9292, ROC AUC: 0.9857, ‚è± Time: 29.55 sec\n",
      "\n",
      "‚úÖ Averaged results with timings saved to 'M4_Averaged_Results.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def tune_classifiers(X_train, y_train, X_test, y_test, use_random_search=False, cv=5, best_params_dict=None):\n",
    "    results = {}\n",
    "\n",
    "    classifiers = {\n",
    "        \"Logistic Regression\": (LogisticRegression(max_iter=1000), {\n",
    "            'clf__C': [0.01, 0.1, 1, 10],\n",
    "            'clf__solver': ['lbfgs', 'liblinear']\n",
    "        }),\n",
    "        \"Naive Bayes\": (GaussianNB(), {}),\n",
    "        \"K-Nearest Neighbors\": (KNeighborsClassifier(), {\n",
    "            'clf__n_neighbors': [3, 5, 7, 11],\n",
    "            'clf__weights': ['uniform', 'distance']\n",
    "        }),\n",
    "        \"Decision Tree\": (DecisionTreeClassifier(random_state=42), {\n",
    "            'clf__max_depth': [15, 25, 35],\n",
    "            'clf__min_samples_split': [2, 5, 10],\n",
    "            'clf__criterion': ['gini', 'entropy']\n",
    "        }),\n",
    "        \"Random Forest\": (RandomForestClassifier(random_state=42), {\n",
    "            'clf__n_estimators': [500, 1000],\n",
    "            'clf__max_depth': [50, None],\n",
    "            'clf__max_features': ['sqrt', 'log2']\n",
    "        }),\n",
    "        \"Extra Trees\": (ExtraTreesClassifier(random_state=42), {\n",
    "            'clf__n_estimators': [100, 300],\n",
    "            'clf__max_depth': [None, 50]\n",
    "        }),\n",
    "        \"AdaBoost\": (AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=3), random_state=42), {\n",
    "            'clf__n_estimators': [100, 200],\n",
    "            'clf__learning_rate': [0.01, 0.1]\n",
    "        }),\n",
    "        \"Gradient Boosting\": (GradientBoostingClassifier(random_state=42), {\n",
    "            'clf__n_estimators': [100, 200],\n",
    "            'clf__learning_rate': [0.05, 0.1],\n",
    "            'clf__max_depth': [3, 4]\n",
    "        }),\n",
    "        \"XGBoost\": (XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42), {\n",
    "            'clf__n_estimators': [100, 200],\n",
    "            'clf__learning_rate': [0.05, 0.1],\n",
    "            'clf__max_depth': [3, 4]\n",
    "        }),\n",
    "        \"LightGBM\": (LGBMClassifier(random_state=242), {\n",
    "            'clf__n_estimators': [100, 200],\n",
    "            'clf__learning_rate': [0.05, 0.1],\n",
    "            'clf__num_leaves': [15, 31]\n",
    "        }),\n",
    "        \"Support Vector Machine\": (SVC(probability=True, random_state=42), {\n",
    "            'clf__C': [0.1, 1],\n",
    "            'clf__gamma': ['scale', 'auto']\n",
    "        }),\n",
    "        \"Neural Network\": (MLPClassifier(max_iter=5000, random_state=42), {\n",
    "            'clf__hidden_layer_sizes': [(50, 10), (100, 50)],\n",
    "            'clf__alpha': [0.005, 0.001],\n",
    "            'clf__learning_rate': ['constant', 'adaptive']\n",
    "        }),\n",
    "    }\n",
    "\n",
    "    for name, (model, param_grid) in classifiers.items():\n",
    "        print(f\"\\nüîß Tuning {name}...\")\n",
    "        model_start = time.time()\n",
    "\n",
    "        if best_params_dict and name in best_params_dict:\n",
    "            # Reuse best params\n",
    "            model_params = {k.replace('clf__', ''): v for k, v in best_params_dict[name].items()}\n",
    "            model.set_params(**model_params)\n",
    "            pipe = Pipeline([('scaler', StandardScaler()), ('clf', model)])\n",
    "            pipe.fit(X_train, y_train)\n",
    "            best_model = pipe\n",
    "            best_params = best_params_dict[name]\n",
    "\n",
    "        else:\n",
    "            # Perform tuning\n",
    "            pipe = Pipeline([('scaler', StandardScaler()), ('clf', model)])\n",
    "            if param_grid:  # only tune if params exist\n",
    "                search = (RandomizedSearchCV(pipe, param_distributions=param_grid, n_iter=10,\n",
    "                                             cv=cv, n_jobs=-1, scoring='accuracy', verbose=0)\n",
    "                          if use_random_search else\n",
    "                          GridSearchCV(pipe, param_grid=param_grid, cv=cv, n_jobs=-1, scoring='accuracy', verbose=0))\n",
    "                search.fit(X_train, y_train)\n",
    "                best_model = search.best_estimator_\n",
    "                best_params = search.best_params_\n",
    "            else:\n",
    "                pipe.fit(X_train, y_train)\n",
    "                best_model = pipe\n",
    "                best_params = {}\n",
    "\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_prob = best_model.predict_proba(X_test) if hasattr(best_model, \"predict_proba\") else None\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        roc = roc_auc_score(y_test, y_prob, multi_class='ovr') if y_prob is not None else np.nan\n",
    "\n",
    "        model_end = time.time()\n",
    "        elapsed_model = model_end - model_start\n",
    "\n",
    "        print(f\"{name} Accuracy: {acc:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, \"\n",
    "              f\"Recall: {recall:.4f}, ROC AUC: {roc:.4f}, ‚è± Time: {elapsed_model:.2f} sec\")\n",
    "\n",
    "        results[name] = {\n",
    "            'accuracy': acc,\n",
    "            'F1 score': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'ROC AUC': roc,\n",
    "            'best_model': best_model,\n",
    "            'best_params': best_params,\n",
    "            'time': elapsed_model\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ---- Load Data ----\n",
    "\n",
    "df=pd.read_csv('M4.csv')\n",
    "X = df.drop(columns=[\"crystal_system\"])\n",
    "y = df[\"crystal_system\"]\n",
    "\n",
    "if y.dtype == 'object':\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "runs = 5\n",
    "aggregated_results = defaultdict(list)\n",
    "best_param_store = {}\n",
    "\n",
    "for i in range(runs):\n",
    "    print(f\"\\n‚è± Run {i+1} of {runs}...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=242 + i, stratify=y\n",
    "    )\n",
    "\n",
    "    if i == 0:\n",
    "        run_results = tune_classifiers(X_train, y_train, X_test, y_test, use_random_search=False, cv=3)\n",
    "        best_param_store = {model_name: result['best_params'] for model_name, result in run_results.items()}\n",
    "    else:\n",
    "        run_results = tune_classifiers(X_train, y_train, X_test, y_test, cv=3, best_params_dict=best_param_store)\n",
    "\n",
    "    for model_name, scores in run_results.items():\n",
    "        aggregated_results[model_name].append(scores)\n",
    "\n",
    "# ---- Averaging across runs ----\n",
    "summary = {}\n",
    "for model, runs_scores in aggregated_results.items():\n",
    "    summary[model] = {\n",
    "        'Avg Accuracy': round(np.mean([r['accuracy'] for r in runs_scores]), 4),\n",
    "        'Avg F1 Score': round(np.mean([r['F1 score'] for r in runs_scores]), 4),\n",
    "        'Avg Precision': round(np.mean([r['precision'] for r in runs_scores]), 4),\n",
    "        'Avg Recall': round(np.mean([r['recall'] for r in runs_scores]), 4),\n",
    "        'Avg ROC AUC': round(np.nanmean([r['ROC AUC'] for r in runs_scores]), 4),\n",
    "        'Avg Time (sec)': round(np.mean([r['time'] for r in runs_scores]), 2),\n",
    "        'Best Params (from first run)': best_param_store[model]\n",
    "    }\n",
    "\n",
    "summary_df = pd.DataFrame(summary).T.reset_index().rename(columns={'index': 'Model'})\n",
    "summary_df.to_csv(\"M4_Averaged_Results.csv\", index=False)\n",
    "\n",
    "print(\"\\n‚úÖ Averaged results with timings saved to 'M4_Averaged_Results.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ax4sznUnEYZ7"
   },
   "source": [
    "**SHAP ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOm-hNVREX78",
    "outputId": "ea72498b-1fe4-46bc-fd12-36433d3e84e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crystal System Classes: ['Cubic', 'Orthorhombic', 'Tetragonal', 'Trigonal']\n",
      "\n",
      "üîπ RandomForest üîπ\n",
      "Accuracy: 0.94\n",
      "üî∏ Saved: shap_outputs/RandomForest_shap_importance.csv\n",
      "‚è± Time taken: 228.75 seconds\n",
      "\n",
      "üîπ ExtraTrees üîπ\n",
      "Accuracy: 0.95\n",
      "üî∏ Saved: shap_outputs/ExtraTrees_shap_importance.csv\n",
      "‚è± Time taken: 591.67 seconds\n",
      "\n",
      "üîπ LGBM üîπ\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6264\n",
      "[LightGBM] [Info] Number of data points in the train set: 9712, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -1.394151\n",
      "[LightGBM] [Info] Start training from score -1.386706\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.378091\n",
      "Accuracy: 0.94\n",
      "üî∏ Saved: shap_outputs/LGBM_shap_importance.csv\n",
      "‚è± Time taken: 13.73 seconds\n",
      "\n",
      "‚úÖ Final combined SHAP CSV saved: shap_outputs/Combined_SHAP_Importance_M4.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "# ===========================\n",
    "# Setup\n",
    "# ===========================\n",
    "df = pd.read_csv('M4.csv')\n",
    "target_column = 'crystal_system'\n",
    "output_dir = \"shap_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Encode categorical features except target\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col != target_column:\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# Store original class names before encoding\n",
    "class_names = list(np.unique(y))\n",
    "print(\"Crystal System Classes:\", class_names)\n",
    "\n",
    "# Encode target if categorical\n",
    "if y.dtype == 'object':\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ===========================\n",
    "# Model dictionary\n",
    "# ===========================\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    \"ExtraTrees\": ExtraTreesClassifier(random_state=42, n_jobs=-1),\n",
    "    \"LGBM\": lgb.LGBMClassifier(random_state=42, n_jobs=-1)\n",
    "}\n",
    "\n",
    "# ===========================\n",
    "# Function to compute SHAP\n",
    "# ===========================\n",
    "def run_shap(model, model_name, scale_factor=1.0):\n",
    "    print(f\"\\nüîπ {model_name} üîπ\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {acc:.2f}\")\n",
    "\n",
    "    # SHAP analysis\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    # Handle SHAP output shapes\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_array = np.mean([np.abs(sv) for sv in shap_values], axis=0)\n",
    "    elif isinstance(shap_values, np.ndarray) and shap_values.ndim == 3:\n",
    "        shap_array = np.mean(np.abs(shap_values), axis=2)\n",
    "    else:\n",
    "        shap_array = np.abs(shap_values)\n",
    "\n",
    "    # Mean importance per feature\n",
    "    mean_importance = (np.mean(shap_array, axis=0)) * scale_factor\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        \"Feature\": X_test.columns,\n",
    "        model_name: mean_importance\n",
    "    }).sort_values(by=model_name, ascending=False)\n",
    "\n",
    "    # Save individual CSV\n",
    "    csv_path = os.path.join(output_dir, f\"{model_name}_shap_importance.csv\")\n",
    "    feature_importance_df.to_csv(csv_path, index=False, float_format=\"%.6f\")\n",
    "    print(f\"üî∏ Saved: {csv_path}\")\n",
    "\n",
    "    # --- SHAP Plot: Top 10 Features ---\n",
    "    top10_features = feature_importance_df.head(10)[\"Feature\"].tolist()\n",
    "    X_test_top10 = X_test[top10_features]\n",
    "\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values_top10 = [sv[:, [X_test.columns.get_loc(f) for f in top10_features]] * scale_factor\n",
    "                             for sv in shap_values]\n",
    "    else:\n",
    "        shap_values_top10 = shap_values[:, [X_test.columns.get_loc(f) for f in top10_features]] * scale_factor\n",
    "\n",
    "    plt.figure()\n",
    "    shap.summary_plot(\n",
    "        shap_values_top10,\n",
    "        X_test_top10,\n",
    "        plot_type=\"bar\",\n",
    "        show=False,\n",
    "        class_names=class_names\n",
    "    )\n",
    "    plt.title(f\"{model_name}\")\n",
    "    plt.gca().set_xlabel(\"\")  # Remove default SHAP label\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plot_path = os.path.join(output_dir, f\"{model_name}_shap_top10_plot.png\")\n",
    "    plt.savefig(plot_path, bbox_inches=\"tight\", dpi=400)\n",
    "    plt.close()\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"‚è± Time taken: {elapsed:.2f} seconds\")\n",
    "\n",
    "    return feature_importance_df\n",
    "\n",
    "# ===========================\n",
    "# Run all models\n",
    "# ===========================\n",
    "rf_importance = run_shap(models[\"RandomForest\"], \"RandomForest\")\n",
    "et_importance = run_shap(models[\"ExtraTrees\"], \"ExtraTrees\")\n",
    "lgbm_importance = run_shap(models[\"LGBM\"], \"LGBM\", scale_factor=0.1)  # ‚¨Ö LGBM scaled\n",
    "\n",
    "# ===========================\n",
    "# Merge into Combined CSV\n",
    "# ===========================\n",
    "combined_df = rf_importance.merge(et_importance, on=\"Feature\").merge(lgbm_importance, on=\"Feature\")\n",
    "combined_df[\"Mean Importance\"] = combined_df[[\"RandomForest\", \"ExtraTrees\", \"LGBM\"]].mean(axis=1)\n",
    "combined_df = combined_df.sort_values(by=\"Mean Importance\", ascending=False)\n",
    "\n",
    "combined_csv = os.path.join(output_dir, \"Combined_SHAP_Importance_M4.csv\")\n",
    "combined_df.to_csv(combined_csv, index=False, float_format=\"%.6f\")\n",
    "print(f\"\\n‚úÖ Final combined SHAP CSV saved: {combined_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "id": "2RCn_SYPKpiM",
    "outputId": "cefc27ef-30ff-4756-94db-941e00645146"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2815453225.py:15: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv('Combined_SHAP_Importance_M4.csv')\n",
    "\n",
    "# Sort by Mean Importance and take top 10\n",
    "top10 = df.sort_values(\"Mean Importance\", ascending=False).head(10)\n",
    "\n",
    "# Plot top 10 features\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(\n",
    "    data=top10,\n",
    "    y=\"Feature\",\n",
    "    x=\"Mean Importance\",\n",
    "    palette=\"viridis\"\n",
    ")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"top10_features_M4.png\", dpi=400)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWoAnhgYLzQ4"
   },
   "source": [
    "**Classification with reduced features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZe8S8mIbnh_",
    "outputId": "79d91a18-66a3-499f-d0fc-ef29f34c983a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MPR_A', 'OF', 'ARR_B', 't', 'r_A12', 'END_A', 'END_B', 'ARR_A', 'BP_A',\n",
       "       'VR_A', 'crystal_system'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('M4.csv')\n",
    "#Features to keep\n",
    "features = [\"MPR_A\",\"OF\",\"ARR_B\",\"t\",\"r_A12\",\"END_A\",\"END_B\",\"ARR_A\",\"BP_A\",\"VR_A\",\"crystal_system\"]\n",
    "df = df[features]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hq2aw47cMmDw",
    "outputId": "c54e648e-62c2-4716-ec4e-e9be7ce71db6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è± Run 1 of 5...\n",
      "\n",
      "üîß Tuning Random Forest...\n",
      "Random Forest Accuracy: 0.8942, F1: 0.8928, Precision: 0.8930, Recall: 0.8942, ROC AUC: 0.9817, ‚è± 346.00 sec\n",
      "\n",
      "üîß Tuning Extra Trees...\n",
      "Extra Trees Accuracy: 0.8999, F1: 0.8988, Precision: 0.8987, Recall: 0.8999, ROC AUC: 0.9832, ‚è± 21.34 sec\n",
      "\n",
      "üîß Tuning LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2472\n",
      "[LightGBM] [Info] Number of data points in the train set: 9712, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Accuracy: 0.9077, F1: 0.9070, Precision: 0.9069, Recall: 0.9077, ROC AUC: 0.9853, ‚è± 30.73 sec\n",
      "\n",
      "‚è± Run 2 of 5...\n",
      "\n",
      "üîß Tuning Random Forest...\n",
      "Random Forest Accuracy: 0.8950, F1: 0.8940, Precision: 0.8937, Recall: 0.8950, ROC AUC: 0.9819, ‚è± 17.33 sec\n",
      "\n",
      "üîß Tuning Extra Trees...\n",
      "Extra Trees Accuracy: 0.9098, F1: 0.9090, Precision: 0.9089, Recall: 0.9098, ROC AUC: 0.9836, ‚è± 4.14 sec\n",
      "\n",
      "üîß Tuning LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2473\n",
      "[LightGBM] [Info] Number of data points in the train set: 9712, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Accuracy: 0.9086, F1: 0.9077, Precision: 0.9077, Recall: 0.9086, ROC AUC: 0.9860, ‚è± 2.56 sec\n",
      "\n",
      "‚è± Run 3 of 5...\n",
      "\n",
      "üîß Tuning Random Forest...\n",
      "Random Forest Accuracy: 0.8958, F1: 0.8950, Precision: 0.8947, Recall: 0.8958, ROC AUC: 0.9840, ‚è± 17.29 sec\n",
      "\n",
      "üîß Tuning Extra Trees...\n",
      "Extra Trees Accuracy: 0.9044, F1: 0.9037, Precision: 0.9033, Recall: 0.9044, ROC AUC: 0.9844, ‚è± 3.86 sec\n",
      "\n",
      "üîß Tuning LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2474\n",
      "[LightGBM] [Info] Number of data points in the train set: 9712, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Accuracy: 0.9135, F1: 0.9130, Precision: 0.9128, Recall: 0.9135, ROC AUC: 0.9881, ‚è± 3.27 sec\n",
      "\n",
      "‚è± Run 4 of 5...\n",
      "\n",
      "üîß Tuning Random Forest...\n",
      "Random Forest Accuracy: 0.8933, F1: 0.8925, Precision: 0.8923, Recall: 0.8933, ROC AUC: 0.9834, ‚è± 18.15 sec\n",
      "\n",
      "üîß Tuning Extra Trees...\n",
      "Extra Trees Accuracy: 0.9003, F1: 0.8995, Precision: 0.8991, Recall: 0.9003, ROC AUC: 0.9837, ‚è± 3.97 sec\n",
      "\n",
      "üîß Tuning LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2471\n",
      "[LightGBM] [Info] Number of data points in the train set: 9712, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Accuracy: 0.9180, F1: 0.9178, Precision: 0.9179, Recall: 0.9180, ROC AUC: 0.9883, ‚è± 3.15 sec\n",
      "\n",
      "‚è± Run 5 of 5...\n",
      "\n",
      "üîß Tuning Random Forest...\n",
      "Random Forest Accuracy: 0.8867, F1: 0.8862, Precision: 0.8860, Recall: 0.8867, ROC AUC: 0.9812, ‚è± 17.83 sec\n",
      "\n",
      "üîß Tuning Extra Trees...\n",
      "Extra Trees Accuracy: 0.8954, F1: 0.8949, Precision: 0.8947, Recall: 0.8954, ROC AUC: 0.9821, ‚è± 3.62 sec\n",
      "\n",
      "üîß Tuning LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2470\n",
      "[LightGBM] [Info] Number of data points in the train set: 9712, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Accuracy: 0.9028, F1: 0.9027, Precision: 0.9029, Recall: 0.9028, ROC AUC: 0.9855, ‚è± 2.67 sec\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Classification: RF, ET, LGBM only ----------------\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def tune_classifiers(X_train, y_train, X_test, y_test, cv=3, best_params_dict=None):\n",
    "    results = {}\n",
    "\n",
    "    classifiers = {\n",
    "        \"Random Forest\": (RandomForestClassifier(random_state=42), {\n",
    "            'clf__n_estimators': [500, 1000],\n",
    "            'clf__max_depth': [50, None],\n",
    "            'clf__max_features': ['sqrt', 'log2']\n",
    "        }),\n",
    "        \"Extra Trees\": (ExtraTreesClassifier(random_state=42), {\n",
    "            'clf__n_estimators': [100, 300],\n",
    "            'clf__max_depth': [None, 50]\n",
    "        }),\n",
    "        \"LightGBM\": (LGBMClassifier(random_state=242), {\n",
    "            'clf__n_estimators': [100, 200],\n",
    "            'clf__learning_rate': [0.05, 0.1],\n",
    "            'clf__num_leaves': [15, 31]\n",
    "        })\n",
    "    }\n",
    "\n",
    "    for name, (model, param_grid) in classifiers.items():\n",
    "        print(f\"\\nüîß Tuning {name}...\")\n",
    "        start = time.time()\n",
    "\n",
    "        if best_params_dict and name in best_params_dict:\n",
    "            # Reuse best params\n",
    "            model_params = {k.replace('clf__', ''): v for k, v in best_params_dict[name].items()}\n",
    "            model.set_params(**model_params)\n",
    "            pipe = Pipeline([('scaler', StandardScaler()), ('clf', model)])\n",
    "            pipe.fit(X_train, y_train)\n",
    "            best_model = pipe\n",
    "            best_params = best_params_dict[name]\n",
    "        else:\n",
    "            # Tune with GridSearch\n",
    "            pipe = Pipeline([('scaler', StandardScaler()), ('clf', model)])\n",
    "            search = GridSearchCV(pipe, param_grid=param_grid, cv=cv, n_jobs=-1, scoring='accuracy', verbose=0)\n",
    "            search.fit(X_train, y_train)\n",
    "            best_model = search.best_estimator_\n",
    "            best_params = search.best_params_\n",
    "\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_prob = best_model.predict_proba(X_test) if hasattr(best_model, \"predict_proba\") else None\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        roc = roc_auc_score(y_test, y_prob, multi_class='ovr') if y_prob is not None else np.nan\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "\n",
    "        print(f\"{name} Accuracy: {acc:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, \"\n",
    "              f\"Recall: {recall:.4f}, ROC AUC: {roc:.4f}, ‚è± {elapsed:.2f} sec\")\n",
    "\n",
    "        results[name] = {\n",
    "            'accuracy': acc,\n",
    "            'F1 score': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'ROC AUC': roc,\n",
    "            'best_model': best_model,\n",
    "            'best_params': best_params,\n",
    "            'time': elapsed\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "X = df.drop(columns=[\"crystal_system\"])\n",
    "y = df[\"crystal_system\"]\n",
    "\n",
    "if y.dtype == 'object':\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ---- Repeated Runs ----\n",
    "runs = 5\n",
    "aggregated_results = defaultdict(list)\n",
    "best_param_store = {}\n",
    "\n",
    "for i in range(runs):\n",
    "    print(f\"\\n‚è± Run {i+1} of {runs}...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=242 + i, stratify=y\n",
    "    )\n",
    "\n",
    "    if i == 0:\n",
    "        run_results = tune_classifiers(X_train, y_train, X_test, y_test, cv=3)\n",
    "        best_param_store = {model_name: result['best_params'] for model_name, result in run_results.items()}\n",
    "    else:\n",
    "        run_results = tune_classifiers(X_train, y_train, X_test, y_test, cv=3, best_params_dict=best_param_store)\n",
    "\n",
    "    for model_name, scores in run_results.items():\n",
    "        aggregated_results[model_name].append(scores)\n",
    "\n",
    "# ---- Averaging results ----\n",
    "summary = {}\n",
    "for model, runs_scores in aggregated_results.items():\n",
    "    summary[model] = {\n",
    "        'Avg Accuracy': round(np.mean([r['accuracy'] for r in runs_scores]), 4),\n",
    "        'Avg F1 Score': round(np.mean([r['F1 score'] for r in runs_scores]), 4),\n",
    "        'Avg Precision': round(np.mean([r['precision'] for r in runs_scores]), 4),\n",
    "        'Avg Recall': round(np.mean([r['recall'] for r in runs_scores]), 4),\n",
    "        'Avg ROC AUC': round(np.nanmean([r['ROC AUC'] for r in runs_scores]), 4),\n",
    "        'Avg Time (sec)': round(np.mean([r['time'] for r in runs_scores]), 2),\n",
    "        'Best Params (from first run)': best_param_store[model]\n",
    "    }\n",
    "\n",
    "summary_df = pd.DataFrame(summary).T.reset_index().rename(columns={'index': 'Model'})\n",
    "summary_df.to_csv(\"M4_reduced_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y73vgF3VSopk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
